{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for:\n",
    "1. Webscrap for cities data\n",
    "2. Save data into cities DataFrame\n",
    "3. Webscrap for population data\n",
    "4. Save data into population DataFrame\n",
    "5. Update cities and population tables with collected data\n",
    "\n",
    "The cities DataFrame should contain:\n",
    "* city_id\n",
    "* population \n",
    "* timestamp_population\n",
    "\n",
    "The population DataFrame should contain:\n",
    "* city_id\n",
    "* city_name\n",
    "* country_code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import of the needed Modules, setting up and checking url, extracting data for soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An easy to use list of European cities to simplify the tasks if needed:\n",
    "url_list = \"https://en.wikipedia.org/wiki/List_of_European_cities_by_population_within_city_limits\"\n",
    "list_response = requests.get(url_list)\n",
    "list_response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actually to be explored cities in a list that can be expanded:\n",
    "cities = [\"Berlin\"]\n",
    "# Base url to be expanded by city names later:\n",
    "url_base = \"https://en.wikipedia.org/wiki/\"\n",
    "# A loop through the city list to get the city url:\n",
    "for city in cities:\n",
    "    url_city_page = requests.get(url_base + city)\n",
    "    # print(url_city_page.status_code) # To see if it works\n",
    "    citysoup = BeautifulSoup(url_city_page.content, \"html.parser\") # Brewing the soup\n",
    "    rawdata = {} # Setting up the DF to reduce to needed stuff\n",
    "    rawdata[\"city\"] = city"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c62e2d0e8abf7e03d5de1dc8eac23fc17ec23d48f7a7e8acd70fd152f0b9a83e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
